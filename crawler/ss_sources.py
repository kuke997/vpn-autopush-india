import os
import requests

def get_ss_links():
    urls_str = os.getenv("SS_SOURCE_URLS", "")
    urls = [url.strip() for url in urls_str.split(",") if url.strip()]
    all_links = []

    for url in urls:
        print(f"ğŸŒ æ­£åœ¨æŠ“å– Shadowsocks è®¢é˜…ï¼š{url}")
        try:
            res = requests.get(url, timeout=10)
            if res.status_code == 200:
                links = res.text.strip().splitlines()
                all_links.extend([l.strip() for l in links if l.strip()])
            else:
                print(f"âš ï¸ {url} è¿”å›çŠ¶æ€ç ï¼š{res.status_code}")
        except Exception as e:
            print(f"âŒ æŠ“å– {url} æ—¶å‡ºé”™ï¼š{e}")

    print(f"ğŸ“¦ æ€»å…±æ”¶é›† Shadowsocks é“¾æ¥æ•°ï¼š{len(all_links)}")
    return all_links
